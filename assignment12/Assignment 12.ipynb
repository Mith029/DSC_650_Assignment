{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b95262a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cur_dir = os.getcwd()\n",
    "dataset_dir = cur_dir + '/img_align_celeba/'\n",
    "\n",
    "# path to training and validation directories\n",
    "train_dir = cur_dir + '/train/'\n",
    "val_dir = cur_dir + '/validation/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f96448-e8e7-4cc6-a78b-72a9b40dbfa9",
   "metadata": {},
   "source": [
    "# Only Run Once"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9369c638-08be-40be-912f-a0684187d1b2",
   "metadata": {},
   "source": [
    "### Splitting dataset into train and validation folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1cd4c99-43a0-443a-80cd-bcf2729abfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating train and validation folder\n",
    "# os.makedirs(train_dir, exist_ok=True)\n",
    "# os.makedirs(val_dir, exist_ok=True)\n",
    "\n",
    "# image_filenames = os.listdir(dataset_dir)\n",
    "\n",
    "# # Shuffle the image file names\n",
    "# random.shuffle(image_filenames)\n",
    "\n",
    "# # Split the image file names into training and validation sets\n",
    "# train_filenames, val_filenames = train_test_split(image_filenames, train_size = 0.80, test_size= 0.20, random_state=42)\n",
    "\n",
    "\n",
    "# # Move the training images to the training directory\n",
    "# for file in train_filenames:\n",
    "#     src = os.path.join(dataset_dir, file)\n",
    "#     dst = os.path.join(train_dir, file)\n",
    "#     shutil.move(src, dst)\n",
    "\n",
    "# # Move the validation images to the validation directory\n",
    "# for file in val_filenames:\n",
    "#     src = os.path.join(dataset_dir, file)\n",
    "#     dst = os.path.join(val_dir, file)\n",
    "#     shutil.move(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5d8b65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67cfef03-5c99-4bf8-92c9-f248775a9912",
   "metadata": {},
   "source": [
    "## Insert title here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d35f5490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 162079 files belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 15:02:00.671995: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [162079]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-05-24 15:02:00.672770: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [162079]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x144 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "dataset = image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    label_mode=None,\n",
    "    image_size=(64, 64),\n",
    "    batch_size=512\n",
    ")\n",
    "\n",
    "# Get the first 5 images from the dataset\n",
    "images = []\n",
    "for batch in dataset.take(1):\n",
    "    images = batch[:5]  # Take only the first 5 images\n",
    "\n",
    "# Display the images\n",
    "plt.figure(figsize=(10, 2))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.imshow(images[i].numpy())\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e52a64-5860-491e-9aca-f2a8cefef064",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
