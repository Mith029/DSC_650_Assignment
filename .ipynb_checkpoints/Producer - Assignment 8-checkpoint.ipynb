{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import uuid\n",
    "\n",
    "from kafka import KafkaProducer, KafkaAdminClient\n",
    "from kafka.admin.new_topic import NewTopic\n",
    "from kafka.errors import TopicAlreadyExistsError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration Parameters \n",
    "\n",
    "> **TODO:** Change the configuration prameters to the appropriate values for your setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap_servers': ['kafka.kafka.svc.cluster.local:9092'],\n",
       " 'first_name': 'Mithil',\n",
       " 'last_name': 'Patel',\n",
       " 'client_id': 'PatelMithil',\n",
       " 'topic_prefix': 'PatelMithil'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = dict(\n",
    "    bootstrap_servers=['kafka.kafka.svc.cluster.local:9092'],\n",
    "    first_name='Mithil',\n",
    "    last_name='Patel'\n",
    ")\n",
    "\n",
    "config['client_id'] = '{}{}'.format(\n",
    "    config['last_name'], \n",
    "    config['first_name']\n",
    ")\n",
    "config['topic_prefix'] = '{}{}'.format(\n",
    "    config['last_name'], \n",
    "    config['first_name']\n",
    ")\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Topic Utility Function\n",
    "\n",
    "The `create_kafka_topic` helps create a Kafka topic based on your configuration settings.  For instance, if your first name is *John* and your last name is *Doe*, `create_kafka_topic('locations')` will create a topic with the name `DoeJohn-locations`.  The function will not create the topic if it already exists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic \"PatelMithil-locations\" already exists\n"
     ]
    }
   ],
   "source": [
    "def create_kafka_topic(topic_name, config=config, num_partitions=1, replication_factor=1):\n",
    "    bootstrap_servers = config['bootstrap_servers']\n",
    "    client_id = config['client_id']\n",
    "    topic_prefix = config['topic_prefix']\n",
    "    name = '{}-{}'.format(topic_prefix, topic_name)\n",
    "    \n",
    "    admin_client = KafkaAdminClient(\n",
    "        bootstrap_servers=bootstrap_servers, \n",
    "        client_id=client_id\n",
    "    )\n",
    "    \n",
    "    topic = NewTopic(\n",
    "        name=name,\n",
    "        num_partitions=num_partitions,\n",
    "        replication_factor=replication_factor\n",
    "    )\n",
    "\n",
    "    topic_list = [topic]\n",
    "    try:\n",
    "        admin_client.create_topics(new_topics=topic_list)\n",
    "        print('Created topic \"{}\"'.format(name))\n",
    "    except TopicAlreadyExistsError as e:\n",
    "        print('Topic \"{}\" already exists'.format(name))\n",
    "    \n",
    "create_kafka_topic('locations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kafka Producer\n",
    "\n",
    "The following code creates a `KafkaProducer` object which you can use to send Python objects that are serialized as JSON.\n",
    "\n",
    "**Note:** This producer serializes Python objects as JSON. This means that object must be JSON serializable.  As an example, Python `DateTime` values are not JSON serializable and must be converted to a string (e.g. ISO 8601) or a numeric value (e.g. a Unix timestamp) before being sent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "producer = KafkaProducer(\n",
    "  bootstrap_servers=config['bootstrap_servers'],\n",
    "  value_serializer=lambda x: json.dumps(x).encode('utf-8')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send Data Function\n",
    "\n",
    "The `send_data` function sends a Python object to a Kafka topic. This function adds the `topic_prefix` to the topic so `send_data('locations', data)` sends a JSON serialized message to `DoeJohn-locations`. The function also registers callbacks to let you know if the message has been sent or if an error has occured. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def on_send_success(record_metadata):\n",
    "    print('Message sent:\\n    Topic: \"{}\"\\n    Partition: {}\\n    Offset: {}'.format(\n",
    "        record_metadata.topic,\n",
    "        record_metadata.partition,\n",
    "        record_metadata.offset\n",
    "    ))\n",
    "    \n",
    "def on_send_error(excp):\n",
    "    print('I am an errback', exc_info=excp)\n",
    "    # handle exception\n",
    "\n",
    "def send_data(topic, data, config=config, producer=producer, msg_key=None):\n",
    "    topic_prefix = config['topic_prefix']\n",
    "    topic_name = '{}-{}'.format(topic_prefix, topic)\n",
    "    \n",
    "    if msg_key is not None:\n",
    "        key = msg_key\n",
    "    else:\n",
    "        key = uuid.uuid4().hex\n",
    "    \n",
    "    producer.send(\n",
    "        topic_name, \n",
    "        value=data,\n",
    "        key=key.encode('utf-8')\n",
    "    ).add_callback(on_send_success).add_errback(on_send_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message sent:\n",
      "    Topic: \"PatelMithil-locations\"\n",
      "    Partition: 0\n",
      "    Offset: 3\n"
     ]
    }
   ],
   "source": [
    "# example_data = dict(\n",
    "#     key1='value1',\n",
    "#     key2='value2'\n",
    "# )\n",
    "\n",
    "# send_data('locations', example_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_json\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/dsc650/data/processed/bdd/locations/'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "data_path = os.path.abspath(\"../../../data/processed/bdd/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+------------------+------------------+------------------+-------------------+------------+------------------+--------+---------+--------------------+-----+\n",
      "|                  id|             ride_id|                uuid|           timestamp|            offset|            course|          latitude|          longitude|     geohash|             speed|accuracy|timelapse|            filename|    t|\n",
      "+--------------------+--------------------+--------------------+--------------------+------------------+------------------+------------------+-------------------+------------+------------------+--------+---------+--------------------+-----+\n",
      "|d602b69361b975ad3...|6ef732ea5d79eeb95...|7901ba7a61704c1bb...|1970-01-01 00:25:...|102.57438001660061|174.02879333496094| 40.75754753567096| -73.79306668914728|dr5xbg9tbvt3| 7.010000228881836|    10.0|    false|2330d18d-4f74-45d...|102.5|\n",
      "|d602b69361b975ad3...|6ef732ea5d79eeb95...|7901ba7a61704c1bb...|1970-01-01 00:25:...|103.57438001660061|       139.5703125|40.757676118696075| -73.79314301927708|dr5xbg9qxjs2| 5.570000171661377|    10.0|    false|2330d18d-4f74-45d...|102.5|\n",
      "|5f0b30f49da18ebc1...|01d87368140cb74ba...|b59f82a2612048079...|1970-01-01 00:25:...|106.38593413651994|27.458276748657227| 40.70763405152195| -74.01304407425238|dr5ref975hfr| 6.679999828338623|    10.0|    false|a0c0bc84-748f-4e7...|106.0|\n",
      "|5f0b30f49da18ebc1...|01d87368140cb74ba...|b59f82a2612048079...|1970-01-01 00:25:...|107.38593413651994|27.460285186767578| 40.70757309121908| -74.01308570218634|dr5ref96f1ek| 4.760000228881836|    10.0|    false|a0c0bc84-748f-4e7...|106.0|\n",
      "|097ec0c2d59a23b76...|9cd83b5a569a73d2e...|a8fab740fe074ef1a...|1970-01-01 00:25:...| 60.16329633059419|       317.4609375| 37.52205021682896|-122.26503320049704|9q9j3y9mf1pk|29.709999084472656|    10.0|    false|65c58848-8a31-4b1...| 60.1|\n",
      "+--------------------+--------------------+--------------------+--------------------+------------------+------------------+------------------+-------------------+------------+------------------+--------+---------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"ParquetDataset\").getOrCreate()\n",
    "df_location = spark.read.parquet(data_path+'/locations/')\n",
    "df_location.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+------------------+-------------+-----------------+------------------+------------+------------------+--------+---------+--------------------+---+\n",
      "|                  id|             ride_id|                uuid|           timestamp|            offset|       course|         latitude|         longitude|     geohash|             speed|accuracy|timelapse|            filename|  t|\n",
      "+--------------------+--------------------+--------------------+--------------------+------------------+-------------+-----------------+------------------+------------+------------------+--------+---------+--------------------+---+\n",
      "|85c61911b7fe2ced1...|6760ffa3f41908695...|dad7eae44e784b549...|1970-01-01 00:25:...|1.0779125295566454|   158.203125|  40.677641336844|-73.81793000742218|dr5x2jpkmtcy| 2.119999885559082|    10.0|    false|d745b92f-aefd-467...|0.0|\n",
      "|58682c5d48cad9d9e...|c9a2b46c9aa515b63...|19b9aa10588646b3b...|1970-01-01 00:25:...| 1.525060886522843|299.619140625|40.76287002542555|-73.96194855681718|dr5ruuwscttz|               0.0|    10.0|    false|e2f795a7-6a7d-450...|0.0|\n",
      "|85c61911b7fe2ced1...|6760ffa3f41908695...|dad7eae44e784b549...|1970-01-01 00:25:...| 5.077912529556645|  159.9609375|40.67788281947438|-73.81804710260948|dr5x2jpmfffw|             11.75|    10.0|    false|d745b92f-aefd-467...|4.5|\n",
      "|58682c5d48cad9d9e...|c9a2b46c9aa515b63...|19b9aa10588646b3b...|1970-01-01 00:25:...|4.5250608865228426|299.619140625|40.76287038067684|-73.96194937863832|dr5ruuwsctv3|               0.0|    10.0|    false|e2f795a7-6a7d-450...|4.5|\n",
      "|85c61911b7fe2ced1...|6760ffa3f41908695...|dad7eae44e784b549...|1970-01-01 00:25:...| 8.077912529556645|   159.609375|40.67819106396351|-73.81819261244854|dr5x2jppxkqj|13.149999618530273|    10.0|    false|d745b92f-aefd-467...|7.8|\n",
      "+--------------------+--------------------+--------------------+--------------------+------------------+-------------+-----------------+------------------+------------+------------------+--------+---------+--------------------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sorting dataframe by 't' for timestamps\n",
    "df_location = df_location.orderBy('t')\n",
    "df_location.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0,\n",
       "  {'id': '85c61911b7fe2ced1000c33c9e932706',\n",
       "   'ride_id': '6760ffa3f41908695d1405b776c3e8d5',\n",
       "   'uuid': 'dad7eae44e784b549c8c5a3aa051a8c7',\n",
       "   'timestamp': datetime.datetime(1970, 1, 1, 0, 25, 7, 320453),\n",
       "   'offset': 1.0779125295566454,\n",
       "   'course': 158.203125,\n",
       "   'latitude': 40.677641336844,\n",
       "   'longitude': -73.81793000742218,\n",
       "   'geohash': 'dr5x2jpkmtcy',\n",
       "   'speed': 2.119999885559082,\n",
       "   'accuracy': 10.0,\n",
       "   'timelapse': False,\n",
       "   'filename': 'd745b92f-aefd-467d-9121-7a71308e8d6d.mov',\n",
       "   't': 0.0}),\n",
       " (0.0,\n",
       "  {'id': '58682c5d48cad9d9e103431d773615bf',\n",
       "   'ride_id': 'c9a2b46c9aa515b632eddc45c4868482',\n",
       "   'uuid': '19b9aa10588646b3bf22c9b4865a7995',\n",
       "   'timestamp': datetime.datetime(1970, 1, 1, 0, 25, 3, 882586),\n",
       "   'offset': 1.525060886522843,\n",
       "   'course': 299.619140625,\n",
       "   'latitude': 40.76287002542555,\n",
       "   'longitude': -73.96194855681718,\n",
       "   'geohash': 'dr5ruuwscttz',\n",
       "   'speed': 0.0,\n",
       "   'accuracy': 10.0,\n",
       "   'timelapse': False,\n",
       "   'filename': 'e2f795a7-6a7d-4500-b5d7-4569de996811.mov',\n",
       "   't': 0.0}),\n",
       " (4.5,\n",
       "  {'id': '85c61911b7fe2ced1000c33c9e932706',\n",
       "   'ride_id': '6760ffa3f41908695d1405b776c3e8d5',\n",
       "   'uuid': 'dad7eae44e784b549c8c5a3aa051a8c7',\n",
       "   'timestamp': datetime.datetime(1970, 1, 1, 0, 25, 7, 320449),\n",
       "   'offset': 5.077912529556645,\n",
       "   'course': 159.9609375,\n",
       "   'latitude': 40.67788281947438,\n",
       "   'longitude': -73.81804710260948,\n",
       "   'geohash': 'dr5x2jpmfffw',\n",
       "   'speed': 11.75,\n",
       "   'accuracy': 10.0,\n",
       "   'timelapse': False,\n",
       "   'filename': 'd745b92f-aefd-467d-9121-7a71308e8d6d.mov',\n",
       "   't': 4.5}),\n",
       " (4.5,\n",
       "  {'id': '58682c5d48cad9d9e103431d773615bf',\n",
       "   'ride_id': 'c9a2b46c9aa515b632eddc45c4868482',\n",
       "   'uuid': '19b9aa10588646b3bf22c9b4865a7995',\n",
       "   'timestamp': datetime.datetime(1970, 1, 1, 0, 25, 3, 882583),\n",
       "   'offset': 4.5250608865228426,\n",
       "   'course': 299.619140625,\n",
       "   'latitude': 40.76287038067684,\n",
       "   'longitude': -73.96194937863832,\n",
       "   'geohash': 'dr5ruuwsctv3',\n",
       "   'speed': 0.0,\n",
       "   'accuracy': 10.0,\n",
       "   'timelapse': False,\n",
       "   'filename': 'e2f795a7-6a7d-4500-b5d7-4569de996811.mov',\n",
       "   't': 4.5}),\n",
       " (7.8,\n",
       "  {'id': '85c61911b7fe2ced1000c33c9e932706',\n",
       "   'ride_id': '6760ffa3f41908695d1405b776c3e8d5',\n",
       "   'uuid': 'dad7eae44e784b549c8c5a3aa051a8c7',\n",
       "   'timestamp': datetime.datetime(1970, 1, 1, 0, 25, 7, 320446),\n",
       "   'offset': 8.077912529556645,\n",
       "   'course': 159.609375,\n",
       "   'latitude': 40.67819106396351,\n",
       "   'longitude': -73.81819261244854,\n",
       "   'geohash': 'dr5x2jppxkqj',\n",
       "   'speed': 13.149999618530273,\n",
       "   'accuracy': 10.0,\n",
       "   'timelapse': False,\n",
       "   'filename': 'd745b92f-aefd-467d-9121-7a71308e8d6d.mov',\n",
       "   't': 7.8})]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting timestamps and info to push messages\n",
    "t_stamps = [(row.t,row.asDict()) for row in df_location.collect()]\n",
    "t_stamps[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
